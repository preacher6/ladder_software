{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "529c9f8759bede575fc3c1c0a7d57d5ffc5b30205a4d6a007108b8ded7bffe54"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.naukri.com/financial-analyst-jobs-in-mumbai?k=financial%20analyst&l=mumbai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary for storing the information after scraping\n",
    "driver = webdriver.Chrome('C:\\selenium\\chromedriver.exe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soup.find(class_='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_elems = results.find_all('article', class_='jobTuple bgWhite br4 mb-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs={\"url\":[],\n",
    "     \"title\":[],\n",
    "     \"company\":[],\n",
    "     \"payment\":[],\n",
    "     \"experience\":[],\n",
    "     \"rating\":[],\n",
    "     \"reviews\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jobs={\"url\":[],\n",
    "     \"title\":[],\n",
    "     \"company\":[],\n",
    "     \"payment\":[],\n",
    "     \"experience\":[],\n",
    "     \"location\":[],\n",
    "     \"skills\":[],\n",
    "     \"rating\":[],\n",
    "     \"reviews\":[]}\n",
    "\n",
    "driver = webdriver.Chrome('C:\\selenium\\chromedriver.exe')\n",
    "for index in range(1, 20):\n",
    "    \n",
    "    driver.get(\"https://www.naukri.com/data-scientist-jobs-{}\".format(index))\n",
    "    time.sleep(3)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html5lib')\n",
    "    results = soup.find(class_='list')\n",
    "    job_elems = results.find_all('article', class_='jobTuple bgWhite br4 mb-8')    \n",
    "    for job_elem in job_elems:\n",
    "        skills = []\n",
    "        url = job_elem.find('a', class_='title fw500 ellipsis').get('href')\n",
    "        jobs['url'].append(url)\n",
    "        title = job_elem.find('a', class_='title fw500 ellipsis').get('title')\n",
    "        jobs['title'].append(title)\n",
    "        company = job_elem.find('a', class_='subTitle ellipsis fleft').get('title')\n",
    "        jobs['company'].append(company)\n",
    "        payment = job_elem.find('li', class_='fleft grey-text br2 placeHolderLi salary').text\n",
    "        jobs['payment'].append(payment)\n",
    "        experience = job_elem.find('li', class_='fleft grey-text br2 placeHolderLi experience')\n",
    "        if experience is None:\n",
    "            jobs['experience'].append('No required')\n",
    "        else:\n",
    "            jobs['experience'].append(experience.text)\n",
    "        location = job_elem.find('li', class_='fleft grey-text br2 placeHolderLi location')\n",
    "        if location is None:\n",
    "            jobs['location'].append('No required')\n",
    "        else:\n",
    "            jobs['location'].append(location.text)\n",
    "        skill_ = job_elem.find('ul', class_='tags has-description')\n",
    "        skill_list = skill_.find_all('li', class_='fleft fs12 grey-text lh16 dot')\n",
    "        for sk_l in skill_list:\n",
    "            skills.append(sk_l.text)\n",
    "        jobs['skills'].append(skills)\n",
    "        rating = job_elem.find('span', class_='starRating fleft dot')\n",
    "        if rating is None:\n",
    "            rating = 'No tiene rating'\n",
    "            jobs['rating'].append(rating)\n",
    "        else:\n",
    "            jobs['rating'].append(rating.text)\n",
    "        reviews = job_elem.find('a', class_='reviewsCount ml-5 fleft blue-text')\n",
    "        if reviews is None:\n",
    "            reviews = 'No tiene reviews'\n",
    "            jobs['reviews'].append(reviews)\n",
    "        else:\n",
    "            jobs['reviews'].append(reviews.text)        \n",
    "\n",
    "df_jobs = pd.DataFrame(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Business Intelligence',\n",
       " 'Artificial Intelligence',\n",
       " 'Natural Language Processing',\n",
       " 'Neural Networks',\n",
       " 'Data Mining',\n",
       " 'Machine Learning',\n",
       " 'Deep Learning',\n",
       " 'SQL']"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "df_jobs.iloc[1]['skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(29, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "df_jobs[df_jobs.duplicated(subset=[\"title\", \"company\", \"experience\", \"payment\", \"location\"])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.drop_duplicates(subset=[\"title\", \"company\", \"experience\", \"payment\", \"location\"], keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['location'] = df_jobs['location'].apply(lambda line: line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = df_jobs.apply(lambda x: x.astype(str).str.lower())"
   ]
  }
 ]
}